#!/bin/bash

#SBATCH --job-name d2q9-bgk
#SBATCH --nodes 4
#SBATCH --ntasks-per-node 28
#SBATCH --time 00:70:00
#SBATCH --partition veryshort
#SBATCH --reservation=COSC026662
#SBATCH --account=COSC026662
#SBATCH --output bench.out
#SBATCH --exclude=compute104,compute105


#make clean
#make


echo Running on host `hostname`
echo Time is `date`
echo Directory is `pwd`
echo Slurm job ID is $SLURM_JOB_ID
echo This job runs on the following machines:
echo `echo $SLURM_JOB_NODELIST | uniq`
e
#! Run the executable
#./d2q9-bgk input_128x128.params obstacles_128x128.dat
#./d2q9-bgk input_128x256.params obstacles_128x256.dat
#./d2q9-bgk input_256x256.params obstacles_256x256.dat
#./d2q9-bgk input_1024x1024.params obstacles_1024x1024.dat

export I_MPI_PIN_DOMAIN=omp

mpirun -np 4 --ppn 1 ./d2q9-bgk input_128x128.params obstacles_128x128.dat
mpirun -np 4 --ppn 1 ./d2q9-bgk input_128x128.params obstacles_128x128.dat
mpirun -np 4 --ppn 1 ./d2q9-bgk input_128x128.params obstacles_128x128.dat

mpirun -np 4 --ppn 1 ./d2q9-bgk input_256x256.params obstacles_256x256.dat
mpirun -np 4 --ppn 1 ./d2q9-bgk input_256x256.params obstacles_256x256.dat
mpirun -np 4 --ppn 1 ./d2q9-bgk input_256x256.params obstacles_256x256.dat

mpirun -np 4 --ppn 1 ./d2q9-bgk input_1024x1024.params obstacles_1024x1024.dat
mpirun -np 4 --ppn 1 ./d2q9-bgk input_1024x1024.params obstacles_1024x1024.dat
mpirun -np 4 --ppn 1 ./d2q9-bgk input_1024x1024.params obstacles_1024x1024.dat

#export OMP_NUM_THREADS=28
#export OMP_PROC_BIND=true
#export OMP_PLACES=cores

#for i in {1..30}; do ./d2q9-bgk /user/home/ra18837/HPC/advanced-hpc-lbm/input_1024x1024.params /user/home/ra18837/HPC/advanced-hpc-lbm/obstacles_1024x1024.dat; done


python3 collate.py

OMP_NUM_THREADS=28 OMP_PROC_BIND=true OMP_PLACES=cores ./openmp input_128x128.params obstacles_128x128.dat


make check
